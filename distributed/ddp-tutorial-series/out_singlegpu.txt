log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json
modelid,cpueventname,cudatime,cudatimenooverlap,inputdims,inputsize,kernelduration,blocksperSM,warpsperSM,stream,grid,block,kernelname
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::linear , 27 , 11 , [[32;20];[1;20];[1]] , [32; 20] , 5 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::elementwise_kernel<128; 2; at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&; at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int; at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&; at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::linear , 27 , 11 , [[32;20];[1;20];[1]] , [32; 20] , 6 ,  , 0.074074075 , 7 , [2; 1; 1] , [8; 16; 1] , std::enable_if<!(false); void>::type internal::gemvx::kernel<int; int; float; float; float; float; false; true; true; false; 7; false; cublasGemvParams<cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float>; float> >(cublasGemvParams<cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float>; float>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::cross_entropy_loss , 93 , 24 , [[32;1];[32;1];[];[];[];[]] , [32; 1] , 5 ,  , 0.037037037 , 7 , [1; 1; 1] , [1; 128; 1] , void (anonymous namespace)::softmax_warp_forward<float; float; float; 0; true; false>(float*; float const*; int; int; int; bool const*; int; bool)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::cross_entropy_loss , 93 , 24 , [[32;1];[32;1];[];[];[];[]] , [32; 1] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 3> >(int; at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 3>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::cross_entropy_loss , 93 , 24 , [[32;1];[32;1];[];[];[];[]] , [32; 1] , 7 ,  , 0.009259259 , 7 , [1; 1; 1] , [32; 1; 1] , void at::native::reduce_kernel<512; 1; at::native::ReduceOp<float; at::native::func_wrapper_t<float; at::native::sum_functor<float; float; float>::operator()(at::TensorIterator&)::{lambda(float; float)#1}>; unsigned int; float; 4> >(at::native::ReduceOp<float; at::native::func_wrapper_t<float; at::native::sum_functor<float; float; float>::operator()(at::TensorIterator&)::{lambda(float; float)#1}>; unsigned int; float; 4>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::cross_entropy_loss , 93 , 24 , [[32;1];[32;1];[];[];[];[]] , [32; 1] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}; at::detail::Array<char*; 2> >(int; at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}; at::detail::Array<char*; 2>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::cross_entropy_loss , 93 , 24 , [[32;1];[32;1];[];[];[];[]] , [32; 1] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::BUnaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 2> >(int; at::native::BUnaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 2>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::ones_like , 4 , 4 , [[];[];[];[];[];[]] , [] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::FillFunctor<float>; at::detail::Array<char*; 1> >(int; at::native::FillFunctor<float>; at::detail::Array<char*; 1>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: DivBackward1 , 4 , 4 , [[]] , [] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::BUnaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 2> >(int; at::native::BUnaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> >; at::detail::Array<char*; 2>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: NegBackward0 , 4 , 4 , [[]] , [] , 4 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::vectorized_elementwise_kernel<4; at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}; at::detail::Array<char*; 2> >(int; at::native::neg_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}; at::detail::Array<char*; 2>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: MulBackward0 , 5 , 5 , [[32;1]] , [32; 1] , 5 ,  , 0.037037037 , 7 , [1; 1; 1] , [128; 1; 1] , void at::native::elementwise_kernel<128; 2; at::native::gpu_kernel_impl<at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&; at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int; at::native::gpu_kernel_impl<at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&; at::native::BinaryFunctor<float; float; float; at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: LogSoftmaxBackward0 , 5 , 5 , [[32;1]] , [32; 1] , 5 ,  , 0.037037037 , 7 , [1; 1; 1] , [1; 128; 1] , void (anonymous namespace)::softmax_warp_backward<float; float; float; 0; true; false>(float*; float const*; float const*; int; int; int; bool const*)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: AddmmBackward0 , 36 , 13 , [[32;1]] , [32; 1] , 6 ,  , 0.22222222 , 7 , [3; 1; 1] , [8; 32; 1] , void gemvNSP_kernel<float; float; float; float; 1; 32; 4; 1024; false; cublasGemvParams<cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float>; float> >(cublasGemvParams<cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float const>; cublasGemvTensorStridedBatched<float>; float>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , autograd::engine::evaluate_function: AddmmBackward0 , 36 , 13 , [[32;1]] , [32; 1] , 7 ,  , 0.009259259 , 7 , [1; 1; 1] , [32; 1; 1] , void at::native::reduce_kernel<512; 1; at::native::ReduceOp<float; at::native::func_wrapper_t<float; at::native::sum_functor<float; float; float>::operator()(at::TensorIterator&)::{lambda(float; float)#1}>; unsigned int; float; 4> >(at::native::ReduceOp<float; at::native::func_wrapper_t<float; at::native::sum_functor<float; float; float>::operator()(at::TensorIterator&)::{lambda(float; float)#1}>; unsigned int; float; 4>)
log/train_singlegpu/nomster_228293.1683906339674.pt.trace.json , aten::_foreach_add_ , 6 , 6 , [[];[];[]] , [] , 6 ,  , 0.2962963 , 7 , [2; 1; 1] , [512; 1; 1] , void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>; at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float; 2; 2; 0>; std::plus<float>; float>(at::native::(anonymous namespace)::TensorListMetadata<2>; at::native::(anonymous namespace)::BinaryOpListAlphaFunctor<float; 2; 2; 0>; std::plus<float>; float)
